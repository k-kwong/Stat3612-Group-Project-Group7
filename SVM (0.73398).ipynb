{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11547483,"sourceType":"datasetVersion","datasetId":7241590}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns                       #visualisation\nimport matplotlib.pyplot as plt             #visualisation\n%matplotlib inline\nsns.set(color_codes=True)","metadata":{"id":"KYz_S21XS7WE","executionInfo":{"status":"ok","timestamp":1745503167394,"user_tz":-480,"elapsed":1150,"user":{"displayName":"Koey C","userId":"09858966441991088365"}},"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:38:41.314192Z","iopub.execute_input":"2025-04-24T16:38:41.314467Z","iopub.status.idle":"2025-04-24T16:38:41.319979Z","shell.execute_reply.started":"2025-04-24T16:38:41.314445Z","shell.execute_reply":"2025-04-24T16:38:41.319189Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# TODO: change this to yours ...\nDATASET_NAME = \"dataset\"  # Change this to your dataset name\nDATA_DIR = f\"/kaggle/input/dataset\"\n\n# read 3 csv files and 1 pkl file\ntrain_csv_file = os.path.join(DATA_DIR, \"train.csv\")\nval_csv_file = os.path.join(DATA_DIR, \"valid.csv\")\ntest_csv_file = os.path.join(DATA_DIR, \"test.csv\")\nehr_pkl_file = os.path.join(DATA_DIR, \"ehr_preprocessed_seq_by_day_cat_embedding.pkl\")\n\ntrain_df = pd.read_csv(train_csv_file)\nval_df = pd.read_csv(val_csv_file)\ntest_df = pd.read_csv(test_csv_file)\n\nwith open(ehr_pkl_file, 'rb') as f:\n    ehr_data = pd.read_pickle(f)","metadata":{"id":"XeulA19PS7WH","executionInfo":{"status":"ok","timestamp":1745503222273,"user_tz":-480,"elapsed":8428,"user":{"displayName":"Koey C","userId":"09858966441991088365"}},"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:38:54.368048Z","iopub.execute_input":"2025-04-24T16:38:54.368318Z","iopub.status.idle":"2025-04-24T16:38:54.940315Z","shell.execute_reply.started":"2025-04-24T16:38:54.368296Z","shell.execute_reply":"2025-04-24T16:38:54.939767Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:38:58.698817Z","iopub.execute_input":"2025-04-24T16:38:58.699077Z","iopub.status.idle":"2025-04-24T16:38:58.704191Z","shell.execute_reply.started":"2025-04-24T16:38:58.699056Z","shell.execute_reply":"2025-04-24T16:38:58.703494Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"#Option 2 Aggregate features by last day\n\nX_train = []\nfor idx, row in train_df.iterrows():\n    X_train.append(ehr_data[\"feat_dict\"][row[\"id\"]][-1])\nX_train = np.array(X_train)\nprint(X_train.shape)\nprint('train_data:',X_train,'\\n')\n\nX_val = []\nfor idx, row in val_df.iterrows():\n    X_val.append(ehr_data[\"feat_dict\"][row[\"id\"]][-1])\nX_val = np.array(X_val)\nprint(X_val.shape)\nprint('validation_data:,',X_val,'\\n')\n\n\n\n\ny_train = train_df['readmitted_within_30days'].values\ny_val = val_df['readmitted_within_30days'].values\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJSRTG96S7WJ","executionInfo":{"status":"ok","timestamp":1745503233635,"user_tz":-480,"elapsed":3143,"user":{"displayName":"Koey C","userId":"09858966441991088365"}},"outputId":"6467126e-a307-4779-af08-f0b2b90064e2","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:39:15.824736Z","iopub.execute_input":"2025-04-24T16:39:15.825161Z","iopub.status.idle":"2025-04-24T16:39:18.202852Z","shell.execute_reply.started":"2025-04-24T16:39:15.825132Z","shell.execute_reply":"2025-04-24T16:39:18.201959Z"}},"outputs":[{"name":"stdout","text":"(49451, 171)\ntrain_data: [[52  1  6 ...  0  0  0]\n [52  1  6 ...  0  0  0]\n [52  1  6 ...  0  0  0]\n ...\n [91  1  6 ...  0  0  1]\n [69  0  6 ...  0  0  0]\n [69  0  6 ...  0  0  0]] \n\n(16721, 171)\nvalidation_data:, [[75  0  6 ...  3  6  0]\n [75  0  6 ...  3  6  0]\n [75  0  6 ...  3  6  0]\n ...\n [77  1  6 ...  0  0  0]\n [49  1  6 ...  0  0  0]\n [49  1  6 ...  0  0  0]] \n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from scipy.stats import pointbiserialr\n# initialize storage for std_devs\nstd_devs = np.std(X_train, axis=0)\n\n\nfeature_names = ehr_data[\"feature_cols\"]\n\n# Create a DataFrame for analysis\nstd_df = pd.DataFrame({\n    \"Feature\": feature_names,\n    \"Std_Dev\": std_devs\n})\n\n\n\n# Initialize storage\ncorrelations = []\np_values = []\n\n\n# Calculate correlation for each feature\nfor i in range(X_train.shape[1]):\n    if np.std(X_train[:, i]) == 0:  # Skip constant features\n        correlations.append(0)\n        p_values.append(1)\n    else:\n        corr, pval = pointbiserialr(X_train[:, i], y_train)\n        correlations.append(corr)\n        p_values.append(pval)\n\n\n\n# Create results DataFrame\ncorr_df = pd.DataFrame({\n    \"Feature\": feature_names,\n    \"Correlation\": correlations,\n    \"P-value\": p_values\n})\n\n\n\n# Sort by absolute correlation strength\ncorr_df[\"Abs_Correlation\"] = np.abs(corr_df[\"Correlation\"])\ncorr_df = corr_df.sort_values(\"Abs_Correlation\", ascending=True)\n\n\n\n# Function to analyze zero-value ratio in features\ndef analyze_zeros(ehr_data, feature_cols, threshold=0.5):\n\n    all_zeros = []\n    for feature_name, feature_idx in zip(feature_cols, range(len(feature_cols))):\n        zeros_count = np.sum([np.sum(matrix[:, feature_idx] == 0) for matrix in ehr_data[\"feat_dict\"].values()])\n        total_values = sum([matrix.shape[0] for matrix in ehr_data[\"feat_dict\"].values()])\n        zero_ratio = zeros_count / total_values\n        if zero_ratio > threshold:\n            all_zeros.append((feature_name, zero_ratio))\n    return pd.DataFrame(all_zeros, columns=[\"Feature\", \"Zero_Ratio\"])\n\n# Analyze zero-value ratio for each feature category\ndemo_zero_df = analyze_zeros(ehr_data, ehr_data[\"demo_cols\"])\nicd_zero_df = analyze_zeros(ehr_data, ehr_data[\"icd_cols\"])\nlab_zero_df = analyze_zeros(ehr_data, ehr_data[\"lab_cols\"])\nmed_zero_df = analyze_zeros(ehr_data, ehr_data[\"med_cols\"])\n\n# Combine all zero-value data\nzero_df = pd.concat([demo_zero_df, icd_zero_df, lab_zero_df, med_zero_df])\n\n# Merge zero-value data with std and correlation data\ncombined_df = pd.merge(pd.merge(std_df, corr_df, on='Feature'), zero_df, on='Feature', how='left')\n\n\n\nclinically_relevant = [\n    # Labs\n    'Creatinine Blood', 'Hemoglobin Blood', 'Hematocrit Blood',\n    'Potassium Blood', 'Sodium Blood', 'Glucose Blood',\n    'Troponin T Blood', 'Platelet Count Blood', 'Eosinophils Blood',\n    'pH Urine', 'pO2 Blood', 'pCO2 Blood', 'Anion Gap Blood',\n\n    # ICD-10\n    'I10-I16', 'N17-N19', 'J09-J18', 'E70-E88', 'I30-I52',\n    'J40-J47', 'B20-B20',\n\n    # Drugs\n    'ANTICOAGULANTS', 'ANTIBIOTICS', 'IMMUNOSUPPRESSANTS',\n    'ANTIINFLAM.TUMOR NECROSIS FACTOR INHIBITING AGENTS'\n]\n\n\nthresholds = {\n    'zero_ratio': {\n        'icd': 0.95,    # ICD codes often sparse\n        'med': 0.95,    # Medications often sparse\n        'lab': 0.95,    # Labs should rarely be zero\n        'demo': 0.9     # Demographics rarely zero\n    },\n    'std_dev': 0.01,    # Only for continuous features\n    'correlation': {\n        'min_abs_corr': 0.01,\n        'max_pvalue': 0.05\n    }\n}\n\n# Categorize features\nfeature_types = {\n    'icd': ehr_data[\"icd_cols\"],\n    'med': ehr_data[\"med_cols\"],\n    'lab': ehr_data[\"lab_cols\"],\n    'demo': ehr_data[\"demo_cols\"]\n}\n\n# Initialize storage\nfeatures_to_remove = []\n\n\n# Check each feature type separately\nfor ftype, cols in feature_types.items():\n    for feature in cols:\n        row = combined_df[combined_df['Feature'] == feature].iloc[0]\n\n        # Skip binary features for variance check\n        check_variance = ftype not in ['icd']\n\n        # Apply type-specific rules\n        if (row['Zero_Ratio'] > thresholds['zero_ratio'][ftype]) and \\\n           (not check_variance or row['Std_Dev'] < thresholds['std_dev']) and \\\n           (np.abs(row['Correlation']) < thresholds['correlation']['min_abs_corr']) and \\\n           (row['P-value'] > thresholds['correlation']['max_pvalue']):\n            features_to_remove.append(feature)\n\n\n\n\nfiltered_df = combined_df[~combined_df['Feature'].isin(clinically_relevant)]\n# Generate report\nremoval_df = filtered_df[filtered_df['Feature'].isin(features_to_remove)].sort_values(\n    by=['Zero_Ratio', 'Std_Dev', 'Abs_Correlation'],\n    ascending=[False, True, True]\n)\n\n# Get indices of features to remove\nfeatures_to_remove = removal_df['Feature'].tolist()\nall_features = ehr_data[\"feature_cols\"]\nremove_indices = [i for i, feature in enumerate(all_features)\n                 if feature in features_to_remove]\n\n#  Function to remove features\ndef remove_features(X, remove_indices):\n    return np.delete(X, remove_indices, axis=1)\n\n#  Apply to both training and validation sets\nX_train_filtered = remove_features(X_train, remove_indices)\nX_val_filtered = remove_features(X_val, remove_indices)\n\n# 4. Get remaining feature names\nremaining_features = [f for i, f in enumerate(all_features)\n                     if i not in remove_indices]\n\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8sV5oB4cS7WK","executionInfo":{"status":"ok","timestamp":1745503251029,"user_tz":-480,"elapsed":14103,"user":{"displayName":"Koey C","userId":"09858966441991088365"}},"outputId":"e80bd66c-268d-4d17-ec07-25b5980a109d","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:39:22.441620Z","iopub.execute_input":"2025-04-24T16:39:22.441892Z","iopub.status.idle":"2025-04-24T16:39:36.246084Z","shell.execute_reply.started":"2025-04-24T16:39:22.441872Z","shell.execute_reply":"2025-04-24T16:39:36.245242Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3908888384.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  zero_df = pd.concat([demo_zero_df, icd_zero_df, lab_zero_df, med_zero_df])\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# print preprocessing result\n\nprint(f\"\\nRecommended features to remove (last) ({len(removal_df)} total):\")\nprint(removal_df[['Feature', 'Zero_Ratio', 'Std_Dev', 'Correlation', 'P-value']])\nprint(\"Recommended removal features list:\")\nprint(removal_df['Feature'].tolist())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rpql_98YS7WL","executionInfo":{"status":"ok","timestamp":1745503260922,"user_tz":-480,"elapsed":50,"user":{"displayName":"Koey C","userId":"09858966441991088365"}},"outputId":"a77d8c9b-486e-463b-fd11-dc97b43b35fe","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:39:41.404870Z","iopub.execute_input":"2025-04-24T16:39:41.405109Z","iopub.status.idle":"2025-04-24T16:39:41.414291Z","shell.execute_reply.started":"2025-04-24T16:39:41.405092Z","shell.execute_reply":"2025-04-24T16:39:41.413508Z"}},"outputs":[{"name":"stdout","text":"\nRecommended features to remove (last) (44 total):\n                        Feature  Zero_Ratio   Std_Dev  Correlation   P-value\n54                      K65-K68    0.999950  0.015576    -0.008536  0.057676\n24                      R40-R46    0.999950  0.102142    -0.003603  0.423045\n8                       M80-M85    0.999909  0.007789    -0.004268  0.342633\n29                      B25-B34    0.999877  0.029816     0.004573  0.309156\n26                      N20-N23    0.999863  0.008993    -0.004928  0.273169\n73                      N60-N65    0.999831  0.025824     0.006283  0.162356\n47                      G89-G99    0.999813  0.182042     0.007699  0.086893\n44                      M50-M54    0.999786  0.000000     0.000000  1.000000\n111       Basophils Joint Fluid    0.999758  0.000000     0.000000  1.000000\n57                      B65-B83    0.999735  0.006359    -0.003484  0.438443\n80                      K40-K46    0.999667  0.000000     0.000000  1.000000\n93                      R90-R94    0.999653  0.000000     0.000000  1.000000\n39                      A20-A28    0.999640  0.000000     0.000000  1.000000\n101     Eosinophils Joint Fluid    0.999631  0.000000     0.000000  1.000000\n15                      H30-H36    0.999631  0.008993    -0.004928  0.273169\n10                      J90-J94    0.999631  0.203612    -0.003009  0.503484\n41                      E89-E89    0.999621  0.008993    -0.004928  0.273169\n70                      K00-K14    0.999553  0.010055    -0.005509  0.220519\n21                      N30-N39    0.999380  0.011014    -0.006035  0.179564\n17                      N00-N08    0.999270  0.000000     0.000000  1.000000\n65                      B50-B64    0.999083  0.038393     0.007682  0.087577\n66                      O60-O77    0.999042  0.000000     0.000000  1.000000\n58                      E40-E46    0.998996  0.216559    -0.000892  0.842838\n82                      Q00-Q07    0.998910  0.006359    -0.003484  0.438443\n127     Lymphocytes Joint Fluid    0.998860  0.000000     0.000000  1.000000\n32                      C73-C75    0.998837  0.006359    -0.003484  0.438443\n77                      M05-M14    0.998764  0.011897    -0.006519  0.147156\n98            Basophils Pleural    0.998714  0.000000     0.000000  1.000000\n7                       F40-F48    0.998714  0.006359    -0.003484  0.438443\n79                      B35-B49    0.998686  0.031782     0.008239  0.066943\n72                      J00-J06    0.998367  0.000000     0.000000  1.000000\n97   Basophils Other Body Fluid    0.998194  0.000000     0.000000  1.000000\n49                      J30-J39    0.997847  0.000000     0.000000  1.000000\n161          PRE-NATAL VITAMINS    0.997774  0.006359    -0.003484  0.438443\n114                     H Blood    0.997163  0.000000     0.000000  1.000000\n23                      F50-F59    0.997163  0.006359    -0.003484  0.438443\n89                      D3A-D3A    0.996880  0.010055    -0.005509  0.220519\n55                      R10-R19    0.996123  0.023360     0.007737  0.085331\n38                      M60-M63    0.996054  0.014913    -0.008172  0.069168\n74                      D37-D48    0.994549  0.038915    -0.002856  0.525432\n51                      Q65-Q79    0.989468  0.000000     0.000000  1.000000\n122           Basophils Ascites    0.980933  0.000000     0.000000  1.000000\n12                      E00-E07    0.973535  0.015576    -0.008536  0.057676\n50                      N25-N29    0.964631  0.000000     0.000000  1.000000\nRecommended removal features list:\n['K65-K68', 'R40-R46', 'M80-M85', 'B25-B34', 'N20-N23', 'N60-N65', 'G89-G99', 'M50-M54', 'Basophils Joint Fluid', 'B65-B83', 'K40-K46', 'R90-R94', 'A20-A28', 'Eosinophils Joint Fluid', 'H30-H36', 'J90-J94', 'E89-E89', 'K00-K14', 'N30-N39', 'N00-N08', 'B50-B64', 'O60-O77', 'E40-E46', 'Q00-Q07', 'Lymphocytes Joint Fluid', 'C73-C75', 'M05-M14', 'Basophils Pleural', 'F40-F48', 'B35-B49', 'J00-J06', 'Basophils Other Body Fluid', 'J30-J39', 'PRE-NATAL VITAMINS', 'H Blood', 'F50-F59', 'D3A-D3A', 'R10-R19', 'M60-M63', 'D37-D48', 'Q65-Q79', 'Basophils Ascites', 'E00-E07', 'N25-N29']\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\nimport joblib\n\n#Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_filtered)\nX_val_scaled = scaler.transform(X_val_filtered)\njoblib.dump(scaler, 'scaler.pkl')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvemnWGMgoBH","executionInfo":{"status":"ok","timestamp":1745503263280,"user_tz":-480,"elapsed":502,"user":{"displayName":"Koey C","userId":"09858966441991088365"}},"outputId":"f8cb7808-6c2c-4381-c9a3-35f1855e4332","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:40:01.702097Z","iopub.execute_input":"2025-04-24T16:40:01.702380Z","iopub.status.idle":"2025-04-24T16:40:01.926342Z","shell.execute_reply.started":"2025-04-24T16:40:01.702360Z","shell.execute_reply":"2025-04-24T16:40:01.925609Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"['scaler.pkl']"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"#Train SVM \nsvm_model = SVC(kernel='rbf', probability=True, random_state=42)\nsvm_model.fit(X_train_scaled, y_train)\n\n# Predict on validation set (for evaluation)\ny_val_pred = svm_model.predict(X_val_scaled)\ny_val_proba = svm_model.predict_proba(X_val_scaled)[:, 1]\n\n# Evaluate the model\nprint(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\nprint(\"Validation AUC-ROC:\", roc_auc_score(y_val, y_val_proba))\nprint(\"Validation F1-Score:\", f1_score(y_val, y_val_pred))\nprint(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:40:14.980801Z","iopub.execute_input":"2025-04-24T16:40:14.981067Z","iopub.status.idle":"2025-04-24T16:56:46.481180Z","shell.execute_reply.started":"2025-04-24T16:40:14.981046Z","shell.execute_reply":"2025-04-24T16:56:46.480378Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.7935530171640452\nValidation AUC-ROC: 0.7181474651715123\nValidation F1-Score: 0.38576512455516015\n\nClassification Report:\n               precision    recall  f1-score   support\n\n       False       0.81      0.95      0.88     12800\n        True       0.64      0.28      0.39      3921\n\n    accuracy                           0.79     16721\n   macro avg       0.72      0.61      0.63     16721\nweighted avg       0.77      0.79      0.76     16721\n\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Step 3: Preprocess test data\ntest_df = pd.read_csv('/kaggle/input/dataset/test.csv')  # Adjust path as needed\nprint(f\"Original test set size: {len(test_df)} rows\")\n\n# Extract unique IDs and keep first occurrence\ntest_ids = test_df['id'].unique()\ntest_df = test_df.drop_duplicates(subset='id', keep='first').set_index('id').loc[test_ids].reset_index()\nprint(f\"Test set size with unique IDs: {len(test_df)} rows\")\n\nX_test = []\nfor idx, row in test_df.iterrows():\n    X_test.append(ehr_data[\"feat_dict\"][row[\"id\"]][-1])\nX_test = np.array(X_test)\n\n# Remove the same features as in training\nX_test_filtered = remove_features(X_test, remove_indices)\n\n# Scale test data\nX_test_scaled = scaler.transform(X_test_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:44:16.775581Z","iopub.execute_input":"2025-04-24T17:44:16.775847Z","iopub.status.idle":"2025-04-24T17:44:16.928728Z","shell.execute_reply.started":"2025-04-24T17:44:16.775828Z","shell.execute_reply":"2025-04-24T17:44:16.928095Z"}},"outputs":[{"name":"stdout","text":"Original test set size: 16293 rows\nTest set size with unique IDs: 2741 rows\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"#probability predictions\ntest_probabilities = svm_model.predict_proba(X_test_scaled)[:, 1]\n\n#Prediction outfile\nsubmission_df = pd.DataFrame({\n    'id': test_df['id'],\n    'readmitted_within_30days': test_probabilities\n})\nprint(f\"Submission DataFrame shape: {submission_df.shape}\")\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file created: submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:44:21.375952Z","iopub.execute_input":"2025-04-24T17:44:21.376209Z","iopub.status.idle":"2025-04-24T17:44:27.213496Z","shell.execute_reply.started":"2025-04-24T17:44:21.376190Z","shell.execute_reply":"2025-04-24T17:44:27.212920Z"}},"outputs":[{"name":"stdout","text":"Submission DataFrame shape: (2741, 2)\nSubmission file created: submission.csv\n","output_type":"stream"}],"execution_count":36}]}